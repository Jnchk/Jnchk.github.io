<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
  <title>How to deploy ceph with ceph-deploy - KillMeBaby</title>
  <meta property="og:title" content="How to deploy ceph with ceph-deploy - KillMeBaby" />
  <meta name="twitter:title" content="How to deploy ceph with ceph-deploy - KillMeBaby" />
  <meta name="description" content="本文介绍如何通过ceph-deploy部署ceph集群。
">
  <meta property="og:description" content="本文介绍如何通过ceph-deploy部署ceph集群。
">
  <meta name="twitter:description" content="本文介绍如何通过ceph-deploy部署ceph集群。
">
  <meta name="author" content="Sarshes"/>
  <link rel='icon' type='image/x-icon' href="https://killmebaby.cc/img/favicon.ico" />
  <meta property="og:site_name" content="KillMeBaby" />
  <meta property="og:url" content="https://killmebaby.cc/posts/2018-02-24-ceph-deployment/" />
  <meta property="og:type" content="article" />
  <meta name="twitter:card" content="summary" />
  <meta name="generator" content="Hugo 0.49.2" />
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
  <link rel="stylesheet" href="/css/style.css" media="all" />
  <link rel="stylesheet" href="/css/syntax.css" media="all" />
  <link rel="stylesheet" href="/css/prism.css" media="all" />
  <link rel="stylesheet" href="/css/custom.css" media="all" />
</head>

<body>

<header class="site-header">
  <nav class="site-navi">
    <h1 class="site-title"><a href="/">KillMeBaby</a></h1>
    <ul class="site-navi-items">
      <li class="site-navi-item-categories"><a href="/categories/" title="Categories">Categories</a></li>
      <li class="site-navi-item-tags"><a href="/tags/" title="Tags">Tags</a></li>
      <li class="site-navi-item-archives"><a href="/archives/" title="Archives">Archives</a></li>
      <li class="site-navi-item-about"><a href="/about/" title="About">About</a></li>
    </ul>
  </nav>
</header>
<hr class="site-header-bottom">

  <div class="main" role="main">
    <article class="article">
      
      
      <h1 class="article-title">How to deploy ceph with ceph-deploy</h1>
      
      <hr class="article-title-bottom">
      <ul class="article-meta">
        <li class="article-meta-date"><time>February 24, 2018</time></li>
        <li class="article-meta-categories">
          <a href="/categories/software-deployment/">
            <i class="fas fa-folder"></i>
            software-deployment
          </a>&nbsp;
        </li>
        <li class="article-meta-tags">
          <a href="/tags/ceph/">
            <i class="fas fa-tag"></i>
            ceph
          </a>&nbsp;
        </li>
        <li class="article-meta-tags">
          <a href="/tags/deployment/">
            <i class="fas fa-tag"></i>
            deployment
          </a>&nbsp;
        </li>
      </ul>
      
<aside class="toc">
  <nav id="TableOfContents">
<ul>
<li><a href="#环境描述">环境描述</a></li>
<li><a href="#安装ceph集群">安装ceph集群</a></li>
<li><a href="#通过ceph-rbd挂载磁盘">通过ceph-rbd挂载磁盘</a></li>
<li><a href="#部署cephfs">部署cephfs</a></li>
<li><a href="#通过cephfs挂载磁盘到本地">通过cephfs挂载磁盘到本地</a></li>
<li><a href="#部署过程中可能遇到的问题">部署过程中可能遇到的问题</a></li>
</ul>
</nav>
</aside>
      <p>本文介绍如何通过ceph-deploy部署ceph集群。
</p>

<h1 id="环境描述">环境描述</h1>

<p>准备三台主机，ceph01，ceph01，ceph02。并且这三台主机都需要准备一个额外的磁盘，如本例中的/dev/sdb。同时，我们还需要为/dev/sdb格式化，并设置免密登录。</p>

<pre><code class="language-bash">$ ssh-keygen
$ ssh-copy-id root@ceph01
$ ssh-copy-id root@ceph02
$ ssh-copy-id root@ceph03
$ mkfs.xfs /dev/sdb  # on three nodes
 
$ apt install ceph-deploy
</code></pre>

<h1 id="安装ceph集群">安装ceph集群</h1>

<p>准备好环境即可通过ceph-deploy部署ceph集群。</p>

<pre><code class="language-bash">$ mkdir my-cluster &amp;&amp; cd my-cluster
$ ceph-deploy new ceph01                   # create cluster
$ ceph-deploy install ceph01 ceph02 ceph03 # install ceph package
$ ceph-deploy mon create-initial           # deploy the initial monitor and gather the keys
$ ceph-deploy admin ceph01 ceph02 ceph03   # copy configuration files to nodes
$ ceph-deploy osd create ceph01:sdb ceph02:sdb ceph03:sdb # create OSDs
</code></pre>

<p>按照上面的部署过程，我们会得到一个monitor+三个osd的ceph集群，并且所有部署操作都是在ceph01上进行的，之后对ceph集群的改动也要在此机器上做。</p>

<p>而因为monitor也部署在ceph01这台机器上，所以外部的请求也要发送到该机器上（比如下面挂载cephfs的例子）。</p>

<p>之后验证集群状态：</p>

<pre><code class="language-bash">$ ceph health
HEALTH_OK
$ ceph -s
    cluster 2e19ebb4-d5a1-4916-a2b8-340a9ccf220a
     health HEALTH_OK
     monmap e1: 1 mons at {ceph01=192.168.73.128:6789/0}
            election epoch 3, quorum 0 ceph01
     osdmap e14: 3 osds: 3 up, 3 in
            flags sortbitwise,require_jewel_osds
      pgmap v33: 64 pgs, 1 pools, 0 bytes data, 0 objects
            100 MB used, 45946 MB / 46046 MB avail
                  64 active+clean
$ ceph df
GLOBAL:
    SIZE       AVAIL      RAW USED     %RAW USED
    46046M     45946M         100M          0.22
POOLS:
    NAME     ID     USED     %USED     MAX AVAIL     OBJECTS
    rbd      0         0         0        15315M           0
</code></pre>

<h1 id="通过ceph-rbd挂载磁盘">通过ceph-rbd挂载磁盘</h1>

<pre><code class="language-bash"># 创建pool，也可以使用默认的pool rdb
$ ceph osd pool create first-pool 8
# 创建rbd
$ rbd create foo --size 128 --image-feature layering --pool first-pool
$ rbd map foo --pool first-pool
/dev/rbd0
$ mkfs -t ext4 /dev/rbd0
$ mount -t ext4 /dev/rbd0 /root/test
</code></pre>

<h1 id="部署cephfs">部署cephfs</h1>

<p>为了使用cephfs，我们需要先部署mds，即metadata server。</p>

<pre><code class="language-bash">$ ceph-deploy mds create ceph01
</code></pre>

<p>之后可以创建相关的pool与filesystem</p>

<pre><code class="language-bash">$ ceph osd pool create cephfs_data 8
$ ceph osd pool create cephfs_metadata 8
 
$ ceph fs new cephfs cephfs_metadata cephfs_data
</code></pre>

<p>通过mds的状态验证创建是否成功</p>

<pre><code class="language-bash">$ ceph mds stat
e7: 1/1/1 up {0=ceph01=up:active}    # 即为正常

$ ceph mds stat
e2: 0/0/1 up     # 即为不正常，需要定位问题
</code></pre>

<h1 id="通过cephfs挂载磁盘到本地">通过cephfs挂载磁盘到本地</h1>

<pre><code class="language-bash"># 在部署主机上拿到admin用户的key文件，否则直接mount会遇到 libceph: error -22 on auth protocol 2 init 类似的错误
# 比如我们拿到key： AQBpMXBat2emEhAAXm6p3Xq0uGtw1qWq9EbEcA==
$ mount -t ceph 192.168.73.128:6789:/ /root/test_cephfs/ -o name=admin,secret=AQBpMXBat2emEhAAXm6p3Xq0uGtw1qWq9EbEcA==
$ df -h
Filesystem                        Size  Used Avail Use% Mounted on
udev                              468M     0  468M   0% /dev
tmpfs                              98M  5.8M   92M   6% /run
/dev/mapper/wille--vg-root         27G  2.1G   24G   8% /
tmpfs                             488M     0  488M   0% /dev/shm
tmpfs                             5.0M     0  5.0M   0% /run/lock
tmpfs                             488M     0  488M   0% /sys/fs/cgroup
/dev/sda1                         472M  106M  342M  24% /boot
/dev/mapper/wille--vg-root--home   20G   45M   19G   1% /home
tmpfs                              98M     0   98M   0% /run/user/0
/dev/rbd0                         120M  1.6M  110M   2% /root/test
192.168.73.128:6789:/              45G  120M   45G   1% /root/test_cephfs
# 然后可以看到cephfs_metadata这个pool中多出了一部分数据
$ ceph df
GLOBAL:
    SIZE       AVAIL      RAW USED     %RAW USED
    46046M     45926M         120M          0.26
POOLS:
    NAME                ID     USED      %USED     MAX AVAIL     OBJECTS
    rbd                 0      8820k      0.06        15307M          15
    first-pool          1          0         0        15307M           0
    cephfs_data         2          0         0        15307M           0
    cephfs_metadata     3       2545         0        15307M          20
# 当我们把一个39M的文件copy到挂载后的目录（/root/test_cephfs）中之后，可以看到cephfs_data中也多出了对应的数据
$ ceph df
GLOBAL:
    SIZE       AVAIL      RAW USED     %RAW USED
    46046M     45814M         232M          0.51
POOLS:
    NAME                ID     USED       %USED     MAX AVAIL     OBJECTS
    rbd                 0       8820k      0.06        15270M          15
    first-pool          1           0         0        15270M           0
    cephfs_data         2      38977k      0.25        15270M          10
    cephfs_metadata     3       37033         0        15270M          20
</code></pre>

<h1 id="部署过程中可能遇到的问题">部署过程中可能遇到的问题</h1>

<p>遇到ceph health提示HEALTH_WARN</p>

<pre><code class="language-bash"># 当我们执行ceph -s时可能遇到下面的错误
$ ceph -s
cluster b3609cba-0b6d-4311-8aa3-6968c0e66f5e
 health HEALTH_WARN
        64 pgs degraded
        64 pgs stuck degraded
        64 pgs stuck unclean
        64 pgs stuck undersized
        64 pgs undersized
 monmap e1: 1 mons at {0=10.11.108.188:6789/0}
        election epoch 3, quorum 0 0
 osdmap e15: 2 osds: 2 up, 2 in
        flags sortbitwise,require_jewel_osds
  pgmap v36: 64 pgs, 1 pools, 0 bytes data, 0 objects
        69172 kB used, 3338 GB / 3338 GB avail
              _64 active+undersized+degraded

# 这一般是我们所使用的/dev/sdb被格式化为了ext4的文件系统
# 在我的实验环境里，通过ceph.conf设置一些全局参数没能解决该问题
# 将/dev/sdb格式化为xfs并重新部署ceph之后即解决了
</code></pre>
    </article>
    <section class="license">
        <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png" /></a>
        <br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
    </section>

    <ul class="pager article-pager">
      <li class="pager-newer">
          <a href="/posts/2018-08-05-kubernetes-deployment-with-kubespray/" data-toggle="tooltip" data-placement="top" title="How to deploy Kubernetes with Kubespray">&lt; Newer</a>
      </li>
      <li class="pager-older">
        <a href="/posts/2018-02-06-redis-cluster-deployment/" data-toggle="tooltip" data-placement="top" title="How to deploy redis cluster">Older &gt;</a>
      </li>
    </ul>


<div class="site-footer">
  <div class="copyright">&copy; Copyright 2017 Sarshes</div>
  <ul class="site-footer-items">
  </ul>
  <div class="powerdby">
    Powered by <a href="https://gohugo.io/">Hugo</a> and <a href="https://github.com/taikii/whiteplain">Whiteplain</a>
  </div>
</div>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>

<script src="/js/fontawesome.js"></script>
<script src="/js/script.js"></script>
<script src="/js/prism.js"></script>
<script src="/js/custom.js"></script>


</body>
</html>
